{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ca83d8e",
   "metadata": {},
   "source": [
    "# first complete the remaining part of this notebook(create a proper rag)\n",
    "\n",
    "\n",
    "\n",
    "# second assisgnment is: take a multiple pdf with text,image,table\n",
    "1. fetch the data from pdf\n",
    "2. at lesat there should be 200 pages\n",
    "3. if chunking(use the sementic chumnking technique) required do chunking and then embedding\n",
    "4. store it inside the vector database(use any of them 1. mongodb 2. astradb 3. opensearch 4.milvus) ## i have not discuss then you need to explore\n",
    "5. create a index with all three index machnism(Flat, HNSW, IVF) ## i have not discuss then you need to explore\n",
    "6. create a retriever pipeline\n",
    "7. check the retriever time(which one is fastet)\n",
    "8. print the accuray score of every similarity search\n",
    "9. perform the reranking either using BM25 or MMR ## i have not discuss then you need to explore\n",
    "10. then write a prompt template\n",
    "11. generte a oputput through llm\n",
    "12. render that output over the DOCx ## i have not discuss then you need to explore\n",
    "as a additional tip: you can follow rag playlist from my youtube\n",
    "\n",
    "after completing it keep it on your github and share that link on my  mail id:\n",
    "snshrivas3365@gmail.com\n",
    "\n",
    "and share the assignment in your community chat as well by tagging krish and sunny\n",
    "\n",
    "deadline is: till firday 9PM\n",
    "   \n",
    "saturday\n",
    "agentic session--> main session\n",
    "langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ff4cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "import faiss\n",
    "import os\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-nano\", api_key=OPENAI_API_KEY)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "# Load and Split Docs\n",
    "loader = PyPDFDirectoryLoader(path=\"pdfs\")\n",
    "docs = loader.load()\n",
    "# text_splitter = SemanticChunker(\n",
    "#     embeddings=embeddings,\n",
    "#     breakpoint_threshold_type=\"percentile\",\n",
    "#     breakpoint_threshold_amount=85.0,\n",
    "#     number_of_chunks=100,\n",
    "#     min_chunk_size=3,\n",
    "#     buffer_size=1\n",
    "# )\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=70)\n",
    "docs_splitted = text_splitter.split_documents(docs)\n",
    "# VectorStore\n",
    "\n",
    "index = faiss.IndexFlatL2(len(embeddings.embed_query(\"hello world\")))\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={}\n",
    ")\n",
    "\n",
    "# Add Docs\n",
    "vector_store.add_documents(documents=docs_splitted)\n",
    "# Similarity Search\n",
    "vector_store.similarity_search_with_score(\"supervised fine tunning\")\n",
    "# Keywords Search\n",
    "keyword_retriever = BM25Retriever.from_documents(docs_splitted)\n",
    "keyword_retriever.k = 3\n",
    "keyword_retriever.invoke(\"supervised fine tunning\")\n",
    "# Pipeline\n",
    "similarity_retriever= vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "hybrid_search_retriever = EnsembleRetriever(retrievers=[similarity_retriever, keyword_retriever], weights=[0.3, 0.7])\n",
    "hybrid_search_retriever.invoke(\"What is SFT(supervised fine tunning)?\")\n",
    "template = \"\"\"\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise. Return the documents that you specically used for your answer. \\nQuestion: {question} \\nContext: {context} \\nAnswer:\")\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "def format_docs(docs):\n",
    "    return \"/n/n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": hybrid_search_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "rag_chain.invoke(\"What is supervised fine tunning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ce04a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reranking_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
